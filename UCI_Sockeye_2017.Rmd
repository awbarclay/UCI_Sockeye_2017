---
title: "2017 UCI sockeye commmercial fishery mixed stock analysis"
author: "Andy Barclay"
date: "May 23, 2018"
output: html_document
---

##Set up workspace
###Get functions and load tidy packages
```{r workspace setup, echo=TRUE}

source("C:\\Users\\awbarclay\\Documents\\R\\GitHubCloneFunctions.R")#GCL functions
source("V:\\Analysis\\Staff\\Andy Barclay\\R\\New Functions\\WorkspaceFolders.GCL.R")#A function I wrote

library("tidyverse")

```

###Create output folders 
```{r create folders, echo=TRUE, message=FALSE}
#WorkspaceFolders.GCL(Folders=c("Output","rubias"),Subfolders=list(rubias=c("baseline","mixture","output")),wd=getwd())

```

###Create locus control and get genotype data
```{r locus control, echo=TRUE}

#CreateLocusControl.GCL(markersuite = "S138_UCI_24SNPs", username ="awbarclay", password = password)#Locus control

#LOKI2R.GCL(sillyvec="SCIMA17",username="awbarclay",password)#Pull Data from LOKI

#save.image("V:/Analysis/2_Central/Sockeye/Cook Inlet/2012 Baseline/Mixture/2017 UCIfisheryMixtures/UCI_Sockeye_2017/UCI_Sockeye_2017.Rdata")

load("V:/Analysis/2_Central/Sockeye/Cook Inlet/2012 Baseline/Mixture/2017 UCIfisheryMixtures/UCI_Sockeye_2017/UCI_Sockeye_2017.Rdata")
```
###Create initial locus object
The Cook Inlet genetic baseline was analyzed for a 96 SNP locus set.  To reduce analysis cost, the locus set was reduced to 24 loci with the highest FST values
```{r initial locus object}

loci24 <- LocusControl$locusnames
loci24

```

##Data cleanup
###Check initial sample size
```{r initial sample size, echo=TRUE}

ColSize<-data.frame(row.names = "SCIMA17")
ColSize$Original_N <- SCIMA17.gcl$n
ColSize

```

###Removing individuals with <80% of loci with gentotypes
Fish that have gentoypes for less than 80% of loci are likely to have poor quality DNA and might introduce gentotyping errors into the mixture data and reduce the accruacy of the mixed stock analysis (MSA)
```{r missloci,echo=TRUE}

MissLOCI=RemoveIndMissLoci.GCL(sillyvec="SCIMA17",proportion=0.8)
MissLOCI

ColSize$AfterMissLoci_N <- SCIMA17.gcl$n
ColSize

```

###Check for duplicate individuals and remove them
Fish with 99% of scores that match
```{r dupckeck, echo=TRUE, message=FALSE}

CheckDupWithinSilly.GCL(sillyvec="SCIMA17",loci=loci24,quantile=NULL,minproportion=0.99)

```
```{r remove duplicate fish,results="hide"}

RemoveIDs.GCL(silly="SCIMA17",IDs=6462)#Remove one of the duplicates

```
```{r final sample size}
ColSize$Final_N <- SCIMA17.gcl$n
ColSize

```

###Combine MHCs and mitochondiral markers
These markers are linked and have to be combined into haploid markers in the baseline analysis; therefore, they have to be combined for the the mixed stock analysis
```{r combine loci,results="hide"}

 CombineLoci.GCL(sillyvec="SCIMA17",markerset=c("One_MHC2_190","One_MHC2_251"),update=TRUE)
 CombineLoci.GCL(sillyvec="SCIMA17",markerset=c("One_CO1","One_Cytb_17","One_Cytb_26"),update=TRUE)

```

###Create locus list for MSA
```{r final locus vector}

loci<-LocusControl$locusnames
loci

```

##Setup mixtures
###Create vector of mixture names
```{r mixvec, echo=FALSE}

mixvec<-c("Drift17","Drift_Corridor17","West_Kalgin17","Northern_Dist17","ESSN17")

```

###Get mixture IDs from attributes and create mixture .gcl objects
```{r attributes table}
attr<-as.tibble(SCIMA17.gcl$attributes)
attr

```

####Drift
```{r Drift (district-wide),results="hide",message=FALSE}

Drift17_IDs<-as.character(filter(attr,CAPTURE_LOCATION=="Drift (district-wide)")$FK_FISH_ID)
PoolCollections.GCL(collections="SCIMA17",loci=loci,IDs=list(SCIMA17=Drift17_IDs),newname="Drift17")

```
```{r Drift (corridor-only),results="hide"}

Drift_Corridor17_IDs<-as.character(filter(attr,CAPTURE_LOCATION=="Drift (expanded corridor-only)")$FK_FISH_ID)
PoolCollections.GCL(collections="SCIMA17",loci=loci,IDs=list(SCIMA17=Drift_Corridor17_IDs),newname="Drift_Corridor17")

```
####Set gillnet
```{r West/Kalgin Island subdistricts,results="hide"}

West_Kalgin17_IDs<-as.character(filter(attr,CAPTURE_LOCATION%in%c("Kalgin Island Subdistrict","Western Subdistrict"))$FK_FISH_ID)
PoolCollections.GCL(collections="SCIMA17",loci=loci,IDs=list(SCIMA17=West_Kalgin17_IDs),newname="West_Kalgin17")

```
```{r Northern District,results="hide"}

Northern_Dist17_IDs<-as.character(filter(attr,CAPTURE_LOCATION%in%c("General Subdistrict (north)","General Subdistrict (south)","Eastern Subdistrict"))$FK_FISH_ID)
PoolCollections.GCL(collections="SCIMA17",loci=loci,IDs=list(SCIMA17=Northern_Dist17_IDs),newname="Northern_Dist17")

```
```{r Upper Subdistrict (ESSN),results="hide"}

ESSN17_IDs<-as.character(filter(attr,CAPTURE_LOCATION%in%c("Cohoe Ninilchik","North K-Beach","South K-Beach","Salamatof"))$FK_FISH_ID)
PoolCollections.GCL(collections="SCIMA17",loci=loci,IDs=list(SCIMA17=ESSN17_IDs),newname="ESSN17")

```
###Check mixture sample sizes
```{r mixture sample sizes,echo=FALSE}

sapply(mixvec,function(mix){get(paste0(mix,".gcl"))$n})

```
###Create rubias mixtures
Creating rubias mixture list object and save as .csv files in the default directory - path = "rubias/mixture"
```{r rubias mixtures, results="hide"}

mixtures <- create_rubias_mixture(sillyvec=mixvec,loci=loci)

```

##Set up baseline
Creating a rubias baseline object save as a .csv file in the default directory - path = "rubias/baseline"
To create the baseline object I had to access objects in the [baseline workspace](V:/Analysis/2_Central/Sockeye/Cook Inlet/2012 Baseline/Baseline) 
```{r rubias baseline,results="hide",message=FALSE}

attach("V:/Analysis/2_Central/Sockeye/Cook Inlet/2012 Baseline/Baseline/CI2012Baseline.RData")#Attach to Baseline data.

groups <- c("Crescent","West","JCL","SusYen","Fish","KTNE","Kenai","Kasilof")#Reporting groups

groupvec <- groupvec#Same length as the number of baseline pops indicating the reporting group for each pop.

GrCol <- colors()[GrCol]#Reporting group colors to use for plotting results

baseline <- create_rubias_baseline(sillyvec=PooledNames71,loci=loci,group_names = groups,groupvec = groupvec,baseline_name = "CI71pops24loci")

detach(pos=match(x="file:V:/Analysis/2_Central/Sockeye/Cook Inlet/2012 Baseline/Baseline/CI2012Baseline.RData",table=search()))#Detach from baseline data.

```
##Analyze mixtures in rubias
Analyzing mixture without using the bias correction (method="MCMC") for 25,000 iterations (reps), burning the first 5,000 iterations (burn_in), and thining (sample_int_Pi) by 10 to reduce the size of the results objects.
```{r anlyze mixtures, results="hide",eval=FALSE}

run_rubias_mixture(reference=baseline,mixture=mixtures,gen_start_col=5, method = "MCMC", 
                   alle_freq_prior = list(const_scaled = 1), reps = 25000, burn_in = 5000, 
                   pb_iter = 100, sample_int_Pi = 10, pi_prior_pseudo_count_sum = 1, 
                   path = "rubias/output")

```

##Get reporting group results
Reading in the rubias traces from .csv files
```{r get results}

repunit_trace<-set_names(lapply(mixvec,function(mix){
  read_csv(paste0("rubias/output/",mix,"_repunit_trace.csv")) %>% 
    mutate(mixture_collection=mix) %>% 
    gather(key="repunit",value="repunit_ppn",Crescent,West,JCL,SusYen,Fish,KTNE,Kenai,Kasilof,-sweep)
  }),mixvec) %>% 
    bind_rows()

```
##Harvest numbers
###Harvest data
Here I'm reading in harvest numbers to apply to the stock compostion estimates to create stock specific harvest esimtate for each mixture. I created an [OceanAK](https://oceanak.dfg.alaska.local) report that pulls sockeye salmon harvest numbers for each fishing day and statisticl area in Cook Inlet.  The results of this report are saved in long format [here](2017 UCI commercial harvest report_5.8.18.csv) 
```{r harvest data, message=FALSE}

harvests<-read_csv("2017 UCI commercial harvest report_5.8.18.csv") %>% 
  select(year="Batch Year", month_day="Date Fishing Began (MM/DD)",gear_type="Gear Name",stat_area="Stat Area",stat_area_name="Stat Area Name",harvest="Number Of Animals (sum)") %>% 
  separate(month_day, c("day","month"), sep="-") %>% 
  mutate(month=sapply(month,function(mo){match(mo, month.abb)})) %>% 
  mutate(date=as.Date(paste(month, day , year, sep = "." ), format = "%m.%d.%Y"))

knitr::kable(head(harvests),caption="2017 UCI commercial sockeye harvests")

```

###Sample dates
Here are the first and last sample date for each capture location
```{r sample dates}
sample_dates<-bind_rows(lapply(mixvec,function(mix){
  
  get(paste0(mix,".gcl"))$attributes %>% 
    as.tibble() %>% 
    group_by(CAPTURE_LOCATION) %>% 
    summarize(min_date=min(CAPTURE_DATE),max_date=max(CAPTURE_DATE))
  
  }))

knitr::kable(sample_dates,caption="Sample Dates")

```


###Represented harvest dates
These are the potential havest dates within 7 days of the first and last sample date to use when calculating represented harvest numbers. If there is more than one capture location for a mixture, use the latest start sample date and the earliest stop sample date for calculating min and max represented dates.  The actual represented harvest dates will be included in the harvest objects for each mixture.
```{r represened harvest dates}

rep_dates<-sapply(mixvec,function(mix){
  
  dates=get(paste0(mix,".gcl"))$attributes %>% 
    as.tibble() %>% 
    group_by(CAPTURE_LOCATION) %>% 
    summarize(min_date=min(CAPTURE_DATE),max_date=max(CAPTURE_DATE));
  
  day=60*60*24;#seconds in a day
  
  week=7*day;#seconds in a week
  
  if(max(dates$min_date)-min(dates$min_date)>7){min_date=min(dates$min_date)}else{min_date=max(dates$min_date)-week};
  
  if(max(dates$max_date)-min(dates$max_date)>7){max_date=max(dates$max_date)}else{max_date=min(dates$max_date)+week};
  
  as.Date(seq(min_date,max_date,by=day))
  
})

knitr::kable(bind_rows(lapply(rep_dates,FUN=range)),caption="Range of Represented Harvest Dates")#Range of represented dates

```

###Calculate harvest represented
Calculating the represented harvest for each mixture.
"One thing to note about the stinking drift data is that there is a wonky stat code (24461), this is an error in the fish ticket database (fishermen put the wrong code in). Usually what we do is lump it in with the previous day's 24460 harvest." (Email from Aaron Dupuis 1/11/2017)
```{r harvest info}

harvest_df<-bind_rows(
  
  #Drift(district-wide)
  harvests %>% filter(stat_area%in%c("24460","24461")&date%in%rep_dates$Drift17)%>% 
    summarise(rep_harvest=sum(harvest),ndays=length(unique(date)),start_date=min(date),end_date=max(date)) %>% 
     mutate(mixture_collection="Drift17",total_harvest=sum(filter(harvests,gear_type=="Drift gillnet"&stat_area%in%c("24460","24461","24510"))$harvest)),#Note: the number of days is 20, but actually it's 15 because of the 24461 stat area, Chinitna Bay (24510) is not represented by the mixture
  
  #Drift(corridor-only)
  harvests %>% filter(gear_type=="Drift gillnet",stat_area%in%c("24456","24457")&date%in%rep_dates$Drift_Corridor17)%>% 
    summarise(rep_harvest=sum(harvest),ndays=length(unique(date)),start_date=min(date),end_date=max(date)) %>% 
     mutate(mixture_collection="Drift_Corridor17",total_harvest=sum(filter(harvests,gear_type=="Drift gillnet"&stat_area%in%c("24456","24457"))$harvest)),
  
  #West/Kalgin subdistricts
  harvests %>% filter(gear_type=="Set gillnet"&stat_area%in%c("24530","24550","24555","24560","24610","24620")&date%in%rep_dates$West_Kalgin17)%>%
    summarise(rep_harvest=sum(harvest),ndays=length(unique(date)),start_date=min(date),end_date=max(date)) %>%
    mutate(mixture_collection="West_Kalgin17",total_harvest=sum(filter(harvests,gear_type=="Set gillnet"&stat_area%in%c("24510","24530","24550","24555","24560","24610","24620"))$harvest)),#Note: Chinitna Bay (24510) is not represented by the mixture
  
   #Northern District
  harvests %>% filter(gear_type=="Set gillnet"&stat_area%in%c("24710","24720","24730","24741","24742","24743","24770","24780","24790")&date%in%rep_dates$Northern_Dist17)%>% 
    summarise(rep_harvest=sum(harvest),ndays=length(unique(date)),start_date=min(date),end_date=max(date)) %>%
    mutate(mixture_collection="Northern_Dist17",total_harvest=sum(filter(harvests,gear_type=="Set gillnet"&stat_area%in%c("24710","24720","24730","24741","24742","24743","24770","24780","24790"))$harvest)),

  #Upper Subdistrict (ESSN)
  harvests %>% filter(gear_type=="Set gillnet"&stat_area%in%c("24421","24422","24431","24432","24441","24442")&date%in%rep_dates$ESSN17)%>% 
    summarise(rep_harvest=sum(harvest),ndays=length(unique(date)),start_date=min(date),end_date=max(date)) %>%
    mutate(mixture_collection="ESSN17",total_harvest=sum(filter(harvests,gear_type=="Set gillnet"&stat_area%in%c("24421","24422","24431","24432","24441","24442"))$harvest))

) %>% 
  mutate(mixture_collection_f=factor(mixture_collection,levels=mixvec)) %>% 
  select(mixture_collection_f,total_harvest,rep_harvest,start_date,end_date,ndays)

knitr::kable(harvest_df)
```

##MSA estimates
###Stock compostions for each mixture
```{r stock comps}

mix.sum.prop<-repunit_trace %>% 
  filter(sweep >= 5000) %>%
  mutate(repunit_f=factor(repunit,levels=groups),mixture_collection_f=factor(mixture_collection,levels=mixvec)) %>% 
  group_by(mixture_collection_f,repunit_f) %>% 
  summarise(lo5CI = quantile(repunit_ppn, probs = 0.05),
            hi95CI = quantile(repunit_ppn, probs = 0.95),
            sd=sd(repunit_ppn),
            mean = mean(repunit_ppn),
            median = quantile(repunit_ppn, probs = 0.5)) 
  
```  
```{r stock harvests}

mix.sum.harvest<-right_join(mix.sum.prop,harvest_df[,c("rep_harvest","mixture_collection_f")],by="mixture_collection_f") %>% 
  group_by(mixture_collection_f,repunit_f) %>% 
  mutate(mean_har=mean*rep_harvest,median_har=median*rep_harvest,sd_har=sd*rep_harvest,lo5CI_har=lo5CI*rep_harvest,hi95CI_har=hi95CI*rep_harvest)

write_excel_csv(mix.sum.harvest %>% 
                  mutate(mean=mean*100,sd=sd*100,lo5CI=lo5CI*100,hi95CI=hi95CI*100) %>% 
                  select(mixture_collection_f,repunit_f,mean,lo5CI,hi95CI,sd,mean_har,lo5CI_har,hi95CI_har,sd_har)
                ,"Output/StockSpecificHarvests_by_mixture.csv")

knitr::kable(head(mix.sum.harvest))
```
 
###Plot mixture estimates
####Barplot
```{r mixture estimate plots, fig.height=11, fig.width=8}

print(
mix.sum.harvest%>% 
  ggplot(aes(x=repunit_f, y = mean_har/1000, fill =repunit_f)) +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))+
  geom_bar(stat="identity",position = "dodge") +
  geom_errorbar(aes(ymin = lo5CI_har/1000, ymax = hi95CI_har/1000, width = 0.3), position = "dodge")+
  scale_fill_manual(name = "Reporting Group", values = GrCol) +
  facet_wrap(~ mixture_collection_f,scales="free_y",ncol=1) +
  ylab("Harvest (thousands)")+
  xlab("Reporting Group")+
  ggtitle("2017 UCI Commerical Sockeye")
)

```

####Bubble plot
Applying harvests to stock composition estimates
```{r unpresented harvests, hide=TRUE,message=FALSE}

mix.sum.harvest_unrep<-harvest_df %>% 
  group_by(mixture_collection_f) %>% 
  summarise(mean_har=total_harvest-rep_harvest,rep_harvest=rep_harvest) %>% 
  mutate(repunit_f="Unrepresented",mean=0,lo5CI=0,hi95CI=0,sd=0,median=0,lo5CI_har=0,hi95CI_har=0,sd_har=0,median_har=0) %>% 
  full_join(mix.sum.harvest) %>% 
  mutate(repunit_f=factor(repunit_f,levels=c(groups,"Unrepresented")),mixture_collection_f=factor(mixture_collection_f,levels=c("Northern_Dist17","West_Kalgin17","Drift17","Drift_Corridor17","ESSN17")[5:1])) %>% 
  arrange(mixture_collection_f,repunit_f)

write_excel_csv(mix.sum.harvest_unrep,"Output/MixtureHarvestSummary.csv")

mix.sum.harvest_unrep

```
Sockeye salmon harvest estimates and harvest not included in the analysis (unanalyzed) by stock (reporting group) and Upper Cook Inlet commercial fishery in 2017. Black circles indicate the portion of the total harvest from each fishery not included in the analysis (unanalyzed).
 
```{r create bubble plot of harvsts, fig.height=5.75, fig.width=9, message=FALSE, warning=FALSE, paged.print=FALSE}
zmax <- max(mix.sum.harvest_unrep$mean, na.rm = TRUE)
bubble_range <- 30


mix.sum.harvest_unrep %>% 
  ggplot(aes(x = repunit_f, y = mixture_collection_f, size = mean, color = repunit_f)) + 
  geom_point() + 
  scale_size_continuous(name = "Harvest", limits = c(0, 1000000), breaks = c(100, 200, 500, 1000, 2000, 5000, 10000, 20000, 50000, 100000,200000,500000), range = c(0, bubble_range), labels = c("100", "200", "500", "1,000", "2,000", "5,000", "10,000", "20,000", "50,000", "100,000","200,000","500,000"))+
  scale_color_manual(values = c(GrCol,"black"), guide = FALSE) +
  scale_x_discrete(name = "Reporting Group", labels = c(groups,"unanalyzed")) +
  scale_y_discrete(name = "Fishery",labels =c("Upper Subdistrict\nset","Drift\n(corridor only)","Drift\n(excluding\ncorridor-only)","Western & Kalgin Island\nsubdistricts\nset","Northern District\nset")  ) + #Strata[c(3,4,2,1,5,6,8,7)]
  theme(axis.text.x = element_text(size = rel(1.2), angle = 90, hjust =.5, vjust = 0.5)) +
  theme(axis.text.y = element_text(size = rel(1.3))) +
  theme(axis.title.y = element_text(size = rel(1.7), angle = 90)) +
  theme(axis.title.x = element_text(size = rel(1.7), angle = 00)) +
  theme(legend.title = element_text(size = rel(1.7), angle = 00)) +
  theme(text = element_text(family = "serif"))

ggsave(filename = "2017HarvestBubblePlot.jpg",plot=last_plot(),device="jpeg",width = 9, height = 5.75,units="in",path=getwd())

```
##Annual harvest estimates
###2017 harvest by stock
```{r annual stratified estimates}

stratified_annual<- repunit_trace %>% 
  filter(sweep >= 5000) %>% 
  mutate(repunit_f = factor(x=repunit,levels=groups))%>%
  full_join(harvest_df, by = c("mixture_collection" = "mixture_collection_f"))%>%
  mutate(mix_repunit_har=repunit_ppn*rep_harvest,UCI_har=sum(unique(rep_harvest)))%>%
  group_by(sweep,repunit_f) %>% 
  summarise(annual_repunit_ppn=sum(mix_repunit_har)/unique(UCI_har),UCI_har=unique(UCI_har)) %>% #Weighted trace
  group_by(repunit_f) %>% 
  summarise(mean = mean(annual_repunit_ppn),
            sd=sd(annual_repunit_ppn),
            lo5CI = quantile(annual_repunit_ppn, probs = 0.05),
            hi95CI = quantile(annual_repunit_ppn, probs = 0.95),
            median = quantile(annual_repunit_ppn, probs = 0.5),
            UCI_har=unique(UCI_har))

```
```{r table annual harvest estimates}
write_excel_csv(stratified_annual %>% 
               group_by(repunit_f) %>% 
               summarise(mean=mean*UCI_har,lo5CI=lo5CI*UCI_har,hi95CI=hi95CI*UCI_har,sd=sd*UCI_har),"Output/AnnualStockSpecificHarvest2017.csv")
               
```


###Get pre 2017 annual estimates
```{r pre 2017 annual}

attach("V:/Analysis/2_Central/Sockeye/Cook Inlet/2012 Baseline/Mixture/2016 UCIfisheryMixtures/2016UCIfisheryMixtureAnalysis.RData")#Attach to 2016 fishery analysis to get overall harvest from 2005-2016
  
Annual05_16 <- as.tibble(cbind(repunit=dimnames(yearlyconv05_16)[[1]],Harvest=as.double(yearlyconv05_16),Year=sort(rep(2005:2016,9)))) %>% 
  mutate(Harvest=as.double(Harvest),repunit_f=factor(repunit,levels=c("Unanalyzed",groups))) 
 
detach()
 
```
###Combine estimates from all years
```{r 2017 unanalyzed}

Unanalyzed<-summarise(harvest_df,Harvest=(sum(total_harvest)-sum(rep_harvest))/1000000) %>% #2017 unanalyzed harvest in millions of fish
  mutate(repunit_f="Unanalyzed")
```
```{r All annual est}

Annual_All<-stratified_annual %>% 
  group_by(repunit_f) %>% 
  summarise(Harvest=(mean*UCI_har)/1000000) %>% 
  bind_rows(Unanalyzed) %>% 
  mutate(repunit_f=factor(repunit_f,levels=c("Unanalyzed",groups)),Year="2017") %>% 
  bind_rows(Annual05_16[,-1])

```


###Stacked bar plot of annual harvests
Overall Cook Inlet commercial fishery stratified harvest estimates for sockeye salmon by stock for 2005-2017.
```{r fig.height=5.75, fig.width=9}

Annual_All %>% 
  ggplot(aes(x=Year,y=Harvest,fill=repunit_f)) +
  geom_bar(stat="identity", position = "stack") +
  scale_fill_manual(name = "Reporting\nGroup", values = c("black",GrCol)) +
  scale_y_continuous(breaks=1:6,limits = c(0, 6)) +
  ylab("Harvest (millions)") +
  theme(axis.text.y = element_text(size = rel(1.3))) +
  theme(axis.title.y = element_text(size = rel(1.7), angle = 90)) +
  theme(axis.title.x = element_text(size = rel(1.7), angle = 00)) +
  theme(legend.title = element_text(size = rel(1.7), angle = 00)) +
  theme(text = element_text(family = "serif"))

ggsave(filename = "AnnualHarvestPlot05_17.jpg",plot=last_plot(),device="jpeg",width = 9, height = 5.75, units="in", path=getwd())

```

##Reporting group summary
```{r reporting group sum}
#How many strata had >5% contribution for each group

  ReportingGroupSum <- mix.sum.harvest %>%
    group_by(repunit_f) %>% 
    summarise(Strata5percent=sum(mean/rep_harvest>=0.05),TotalContribution=sum(mean),PercentSampledHarvest=sum(mean)/sum(rep_harvest))
    
 percent_total_harvest<-mix.sum.harvest %>% 
   mutate(total_rep_harvest=sum(harvest_df$rep_harvest)) %>% 
   group_by(mixture_collection_f,repunit_f) %>% 
   summarise(prop_total=mean/total_rep_harvest*100) %>% 
   spread(mixture_collection_f,prop_total)
   

```

##Harvest appendix
###Upper Subdistrict
```{r Upper Subdistrict}
write_excel_csv(

harvests %>% filter(gear_type=="Set gillnet"&stat_area%in%c("24421","24422","24431","24432","24441","24442")) %>% 
  select(-stat_area_name,-year, -day,-month,-gear_type) %>% 
  spread(stat_area,harvest),

"Output/UppperSubdistrictHarvests.csv")
   
```
###WestKaglinIsland subdistricts
```{r West&Kalgin}
write_excel_csv(

harvests %>% filter(gear_type=="Set gillnet"&stat_area%in%c("24510","24530","24540","24550","24555","24560","24610","24620")) %>% 
  select(-stat_area_name,-year, -day,-month,-gear_type) %>% 
  spread(stat_area,harvest),

"Output/WestKaginSubdistrictsHarvests.csv")
   
```
###Northern District
```{r Northern District}
write_excel_csv(

harvests %>% filter(gear_type=="Set gillnet"&stat_area%in%c("24710","24720","24730","24741","24742","24743","24770","24780","24790")) %>% 
  select(-stat_area_name,-year, -day,-month,-gear_type) %>% 
  spread(stat_area,harvest),

"Output/NorthernDistrictHarvests.csv")
   
```
###Central District Drift
```{r Central District Drift}
write_excel_csv(

harvests %>% filter(gear_type=="Drift gillnet"&stat_area%in%c("24456","24457","24460","24461","24510")) %>% 
  select(-stat_area_name,-year, -day,-month,-gear_type) %>% 
  spread(stat_area,harvest),

"Output/CentralDistrictDriftHarvests.csv")
   
```


